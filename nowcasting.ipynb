{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "from scipy.linalg import eigh, block_diag\n",
    "from numpy.linalg import inv, det, pinv\n",
    "from numpy import kron, log, eye, diag\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "from pandas.tseries.offsets import MonthBegin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InitCond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InitCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def InitCond(X, r, p, spec, blocks, optNaN, Rcon, q):\n",
    "    \n",
    "    nQ = sum(spec.Frequency.eq('q'));   # Number of quarterly series\n",
    "    Qv = spec.loc[spec.Frequency.eq('q')].index.tolist()\n",
    "    Mv = spec.loc[spec.Frequency.eq('m')].index.tolist()\n",
    "\n",
    "    pC = Rcon.shape[1]    # 5, 'tent' structure size (quarterly to monthly)\n",
    "    ppC = max(p, pC)\n",
    "\n",
    "    # OPTS = pd.Series({'disp':0}) # turns off diagnostic information for eigenvalue computation\n",
    "    xBal, indNaN = remNaNs_spline(X, optNaN)\n",
    "\n",
    "    T, N = xBal.shape\n",
    "\n",
    "    xNaN = xBal.copy()\n",
    "    xNaN[indNaN] = np.nan   # set missing values equal to NaN\n",
    "\n",
    "    res = xBal.copy()\n",
    "    resNaN = xNaN.copy()\n",
    "\n",
    "    # Initialize model coefficient output\n",
    "    # C = np.empty((25, 0), int)\n",
    "    C = pd.DataFrame()\n",
    "    A = pd.DataFrame()\n",
    "    Q = pd.DataFrame()\n",
    "    V_0 = pd.DataFrame()\n",
    "\n",
    "    # Set the first observations as NaNs: For quarterly-monthly aggreg. scheme\n",
    "    indNaN.iloc[:pC-1, :] = True\n",
    "\n",
    "    for r_i, b in zip(r, blocks.columns):    # loop for each block\n",
    "\n",
    "        # Observation eq.\n",
    "        C_i = pd.DataFrame(np.zeros((N, r_i*ppC)), index=spec.index)\n",
    "        # lags = [0, 1, ..., ppC], factors = [1, 2, ..., r_i]\n",
    "        C_i.columns = pd.MultiIndex.from_product([range(ppC), range(1, r_i+1)]) \n",
    "        idx_iM = blocks.loc[spec.Frequency.eq('m') & blocks[b].eq(1)].index\n",
    "        idx_iQ = blocks.loc[spec.Frequency.eq('q') & blocks[b].eq(1)].index\n",
    "\n",
    "        # Return eigenvectors v with largest r_i eigenvalues d\n",
    "        d, v = eigh(res.loc[:, idx_iM].cov(), subset_by_index=[idx_iM.shape[0]-r_i, idx_iM.shape[0]-1])\n",
    "        v = pd.DataFrame(v, index=idx_iM, columns=list(range(1, r_i+1)))\n",
    "\n",
    "        # Flip sign for cleaner output. Gives equivalent results without this section\n",
    "        v *= ((sum(v.squeeze()) > 0) * 2 - 1)\n",
    "\n",
    "        # For monthly series with loaded blocks (rows), replace with eigenvector\n",
    "        # This gives the loading\n",
    "        C_i.loc[idx_iM, 0] = pd.concat([v], axis=1, keys=[0])\n",
    "        f = res.loc[:, idx_iM].dot(v);  # Data projection for eigenvector direction\n",
    "        F = pd.DataFrame(index=X.iloc[ppC-1:].index)\n",
    "\n",
    "        # Lag matrix using loading. This is later used for quarterly series\n",
    "        for kk in range(max(p+1, pC)):\n",
    "            f_lag = pd.concat([f.shift(kk)], axis=1, keys=[kk])\n",
    "            F = pd.concat([F, f_lag], axis=1, join='inner')\n",
    "\n",
    "        Rcon_i = np.kron(Rcon, np.eye(r_i))  # Quarterly-monthly aggregate scheme\n",
    "        q_i = np.kron(q, np.zeros(r_i))      # Rcon_i * C_i = q_i\n",
    "\n",
    "        # Produces projected data with lag structure (so pC-1 fewer entries)\n",
    "        ff = F.iloc[:, :r_i*pC]\n",
    "        \n",
    "\n",
    "        for j in idx_iQ: # Loop for quarterly variables\n",
    "            # For series j, values are dropped to accommodate lag structure\n",
    "            xx_j = resNaN[j].iloc[pC-1:].copy()\n",
    "\n",
    "            if (~xx_j.isnull()).sum().squeeze() < ff.shape[1] + 2:\n",
    "                xx_j = res[j].iloc[pC-1:]              # Replaces xx_j with spline if too many NaNs\n",
    "\n",
    "            ff_j = ff.loc[~xx_j.isnull(), :]\n",
    "\n",
    "            xx_j = xx_j.loc[~xx_j.isnull()]\n",
    "            iff_j = inv(ff_j.T.dot(ff_j))\n",
    "\n",
    "            Cc = iff_j.dot(ff_j.T).dot(xx_j)    # least squares\n",
    "\n",
    "            # Spline data monthly to quarterly conversion\n",
    "            Cc = Cc - iff_j.dot(Rcon_i.T).dot(inv(Rcon_i.dot(iff_j).dot(Rcon_i.T))).dot(Rcon_i.dot(Cc))\n",
    "            # Cc = Cc - iff_j.dot(Rcon_i.T).dot(inv(Rcon_i.dot(iff_j).dot(Rcon_i.T))).dot((Rcon_i.dot(Cc)-q_i))\n",
    "\n",
    "            C_i.loc[j].iloc[:pC*r_i] = Cc\n",
    "\n",
    "            \n",
    "        # Zeros in first pC-1 entries (replace dropped from lag)\n",
    "        ff = pd.concat([pd.DataFrame(0, index=res.iloc[:pC-1].index, columns=ff.columns), ff], axis=0)\n",
    "\n",
    "        # Residual calculations\n",
    "        res = res.values - ff.dot(C_i.T)\n",
    "        resNaN = res.copy()\n",
    "        resNaN[indNaN] = np.nan\n",
    "\n",
    "        C = pd.concat([C, pd.concat([C_i], axis=1, keys=[b])], axis=1)\n",
    "\n",
    "        F.columns = pd.MultiIndex.from_tuples(F.columns)\n",
    "        F.columns.names = ['p', 'f']\n",
    "\n",
    "        ## Transition equation\n",
    "        z = F.loc[:, 0]    # Projected data (no lag)\n",
    "        Z = F.loc[:, 1:p]  # Data with lag 1\n",
    "\n",
    "        # Initialize transition matrix\n",
    "        # f_t = A * f_(t-1)\n",
    "        A_i = pd.DataFrame(0, index=F.columns, columns=[(i+1,j) for i,j in F.columns])\n",
    "        A_i.columns = pd.MultiIndex.from_tuples(A_i.columns)\n",
    "        A_temp = inv(Z.T.dot(Z)).dot(Z.T).dot(z)   # OLS coefficient of AR(p)\n",
    "\n",
    "        A_i.loc[idx[0, :], idx[:p, :]] = A_temp.T\n",
    "        A_i.loc[idx[1:, :], idx[:(ppC-1), :]] = np.eye(r_i*(ppC-1))\n",
    "\n",
    "        Q_i = pd.DataFrame(0, index=F.columns, columns=F.columns)\n",
    "        e = z.squeeze() - Z.dot(A_temp).squeeze()                  # VAR residuals\n",
    "        Q_i.loc[0, 0] = np.cov(e, rowvar=False)                    # VAR covariance matrix\n",
    "\n",
    "        initV_i = inv(eye((r_i*ppC)**2)-kron(A_i,A_i)).dot(Q_i.values.flatten('F')).reshape(r_i*ppC,r_i*ppC,order='F')\n",
    "        initV_i = pd.DataFrame(initV_i, index=Q_i.index, columns=Q_i.columns)\n",
    "\n",
    "        # Gives top left block for the transition matrix\n",
    "        A = bdkg_index(A, A_i, b)\n",
    "        Q = bdkg_index(Q, Q_i, b)\n",
    "        V_0 = bdkg_index(V_0, initV_i, b)\n",
    "        \n",
    "\n",
    "    for df in [A, Q, V_0]:\n",
    "        df.index = pd.MultiIndex.from_tuples(df.index)\n",
    "        df.columns = pd.MultiIndex.from_tuples(df.columns)\n",
    "\n",
    "\n",
    "    # C = [C Cm Cy]\n",
    "    Cm = pd.DataFrame(np.eye(N), index=spec.index, columns=spec.index).loc[:, Mv]\n",
    "    Cm.columns = pd.MultiIndex.from_product([Cm.columns, [0], [1]])\n",
    "    C = pd.concat([C, Cm], axis=1)\n",
    "\n",
    "    Cy = pd.DataFrame(0, index=spec.index, columns=pd.MultiIndex.from_product([Qv, range(pC), [1]]))\n",
    "    for j in Qv:\n",
    "        Cy.loc[j, j] = [1, 2, 3, 2, 1]\n",
    "\n",
    "    # Monthly-quarterly aggregate scheme\n",
    "    C = pd.concat([C, Cy], axis=1)\n",
    "    R = pd.DataFrame(np.diag(np.var(resNaN)), index=resNaN.columns, columns=resNaN.columns)\n",
    "\n",
    "    BM = pd.DataFrame(0, index=Mv, columns=Mv);        # Initialize monthly transition matrix values\n",
    "    SM = pd.DataFrame(0, index=Mv, columns=Mv);        # Initialize monthly residual covariance matrix values\n",
    "\n",
    "    for v in Mv:\n",
    "        # Set observation equation residual covariance matrix diagonal\n",
    "        R.loc[v, v] = 1e-04;\n",
    "\n",
    "        # Subsetting series residuals for series i\n",
    "        res_i = resNaN.loc[:, v].copy();\n",
    "\n",
    "        # Returns number of leading/ending zeros\n",
    "        rem_i = res_i.isnull()\n",
    "        leadZero = rem_i.cumsum() == list(range(1, rem_i.shape[0]+1))\n",
    "        endZero = (rem_i.sum() - rem_i.cumsum() + rem_i) == list(range(rem_i.shape[0], 0, -1))\n",
    "\n",
    "        # Truncate leading and ending zeros\n",
    "        res_i = res.loc[:, [v]].copy();\n",
    "        res_i = res_i.loc[~leadZero & ~endZero]\n",
    "\n",
    "        # Linear regression: AR 1 process for monthly series residuals\n",
    "        BM.loc[[v], [v]] = inv(res_i.iloc[:-1].T.dot(res_i.iloc[:-1])).dot(res_i.iloc[:-1].T).dot(res_i.iloc[1:])\n",
    "        SM.loc[[v], [v]] = (res_i-res_i.shift(1).dot(BM.loc[[v],[v]])).cov();  # Residual covariance matrix\n",
    "\n",
    "    sig_e = pd.DataFrame(0, index=Qv, columns=['sig']) \n",
    "\n",
    "    for v in Qv:\n",
    "        sig_e.loc[v] = R.loc[v, v] / 19.0\n",
    "        R.loc[v, v] = 1e-04                 # Covariance for obs matrix residuals\n",
    "\n",
    "    # For BQ, SQ\n",
    "    rho0 = 0.1;\n",
    "    temp = np.zeros((5,5));\n",
    "    temp[0,0] = 1;\n",
    "\n",
    "    # Blocks for covariance matrices\n",
    "    SQ = kron(np.diag((1-rho0**2)*sig_e.squeeze()), temp)\n",
    "    BQ = kron(np.eye(nQ), np.append([[rho0, 0, 0, 0, 0]], \n",
    "                                    np.append(np.eye(4), np.zeros((4,1)), axis=1), axis=0))\n",
    "    initViQ = inv(np.eye((ppC*nQ)**2)-kron(BQ,BQ)).dot(SQ.flatten('F')).reshape(ppC*nQ,ppC*nQ)\n",
    "    initViM = np.diag(1/np.diag(np.eye(BM.shape[0])-BM**2))*SM\n",
    "\n",
    "    BQ = pd.DataFrame(BQ, index=pd.MultiIndex.from_product([Qv, range(pC)]), \n",
    "                      columns=pd.MultiIndex.from_product([Qv, range(1, pC+1)]))\n",
    "\n",
    "    SQ = pd.DataFrame(SQ, index=pd.MultiIndex.from_product([Qv, range(pC)]), \n",
    "                      columns=pd.MultiIndex.from_product([Qv, range(pC)]))\n",
    "\n",
    "    initViQ = pd.DataFrame(initViQ, index=pd.MultiIndex.from_product([Qv, range(pC)]), \n",
    "                           columns=pd.MultiIndex.from_product([Qv, range(pC)]))\n",
    "\n",
    "    # Output\n",
    "    BM.index = BM.columns = Cm.columns\n",
    "    BQ.index = BQ.columns = Cy.columns\n",
    "    SM.index = SM.columns = Cm.columns\n",
    "    SQ.index = SQ.columns = Cy.columns\n",
    "    initViM.index = initViM.columns = Cm.columns\n",
    "    initViQ.index = initViQ.columns = Cy.columns\n",
    "    \n",
    "    A = bkdg_flat_index(bkdg_flat_index(A, BM), BQ)                # Observation matrix\n",
    "    Q = bkdg_flat_index(bkdg_flat_index(Q, SM), SQ)                # Residual covariance matrix (transition)\n",
    "    Z_0 = pd.Series(np.zeros(A.shape[0]), index=A.index)           # States\n",
    "    V_0 = bkdg_flat_index(bkdg_flat_index(V_0, initViM), initViQ)  # Covariance of states\n",
    "    \n",
    "    A.index = A.columns = pd.MultiIndex.from_tuples(A.index)\n",
    "    Q.index = Q.columns = pd.MultiIndex.from_tuples(Q.index)\n",
    "    V_0.index = V_0.columns = pd.MultiIndex.from_tuples(Q.index)\n",
    "    Z_0.index = pd.MultiIndex.from_tuples(Q.index)\n",
    "\n",
    "    return A, C, Q, R, Z_0, V_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_spec, load_data, nanLE, bdkg_index, bdkg_flat_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     28,
     70,
     79,
     85
    ]
   },
   "outputs": [],
   "source": [
    "def load_spec(filename):\n",
    "    spec = pd.read_excel(filename, sheet_name='spec');\n",
    "\n",
    "    # keep variables with Model == 1 and drop 'Model' column\n",
    "    spec = spec.loc[spec.Model.eq(1)].drop('Model', axis=1)\n",
    "\n",
    "    spec_sort = pd.DataFrame()\n",
    "    for f in ['d', 'w', 'm', 'q', 'sa', 'a']:\n",
    "        spec_sort = pd.concat([spec_sort, spec.loc[spec.Frequency.eq(f)]], axis = 0)\n",
    "\n",
    "    UnitsTransformed_dict = {'lin':'Levels (No Transformation)', 'chg':'Change (Difference)',\n",
    "                             'ch1':'Year over Year Change (Difference)', 'pch':'Percent Change',\n",
    "                             'pc1':'Year over Year Percent Change', 'pca':'Percent Change (Annual Rate)',\n",
    "                             'cch':'Continuously Compounded Rate of Change', \n",
    "                             'cca':'Continuously Compounded Annual Rate of Change', 'log':'Natural Log'}\n",
    "\n",
    "    spec_sort['UnitsTransformed'] = spec_sort['Transformation']\n",
    "    spec_sort['UnitsTransformed'] = spec_sort['UnitsTransformed'].replace(UnitsTransformed_dict)\n",
    "    spec_sort = spec_sort.set_index('SeriesID')\n",
    "    Blocks = spec_sort.filter(regex='^Block', axis=1)\n",
    "    Blocks.columns = [i for j,i in Blocks.columns.str.split('-').tolist()]\n",
    "    \n",
    "    spec_sort = spec_sort[spec_sort.columns.drop(list(spec_sort.filter(regex='Block')))]\n",
    "    spec_sort = pd.concat([spec_sort], axis=1, keys=['Spec'])\n",
    "    Blocks = pd.concat([Blocks], axis=1, keys=['Blocks'])\n",
    "\n",
    "    return pd.concat([spec_sort, Blocks], axis=1)\n",
    "\n",
    "def load_data(datafile, Spec, sample_start):\n",
    "    Z = pd.read_excel(datafile, sheet_name='data')\n",
    "    Z = Z.set_index('Date')\n",
    "    Z = Z.asfreq('MS')\n",
    "\n",
    "    if Z.dropna(how='all', axis=0).shape[0] != Z.shape[0]:\n",
    "        print('Data file has missing dates.')\n",
    "\n",
    "        Z.index.names = ['Time']\n",
    "    Z = Z.loc[:, Spec.index]\n",
    "\n",
    "    T, N = Z.shape\n",
    "\n",
    "    f2m = dict(zip(['m', 'q', 'sa', 'a'], [1, 3, 6, 12])) # \n",
    "    f2a = dict(zip(['m', 'q', 'sa', 'a'], [12, 4, 2, 1])) # \n",
    "\n",
    "    X = pd.DataFrame(np.nan, index=Z.index, columns=Z.columns)\n",
    "\n",
    "    for var in Z.columns:\n",
    "        formular = Spec.Spec.loc[var, 'Transformation']\n",
    "        freq = Spec.Spec.loc[var, 'Frequency']\n",
    "        if formular == 'lin':   # Levels (No Transformation)\n",
    "            X.loc[:, var] = Z.loc[:, var]\n",
    "        elif formular == 'chg': # Change (Difference)\n",
    "            X.loc[:, var] = Z.loc[:, var].diff(f2m[freq])\n",
    "        elif formular == 'ch1': # YoY Change (Difference)\n",
    "            X.loc[:, var] = Z.loc[:, var].diff(12)\n",
    "        elif formular == 'pch': # Percent Change\n",
    "            X.loc[:, var] = Z.loc[:, var].pct_change(f2m[freq], fill_method=None) * 100\n",
    "        elif formular == 'pc1': # YoY Percent Change\n",
    "            X.loc[:, var] = Z.loc[:, var].pct_change(12, fill_method=None) * 100\n",
    "        elif formular == 'pca': # Percent Change (annualised)\n",
    "            X.loc[:, var] = ((Z.loc[:, var].pct_change(f2m[freq], fill_method=None) + 1)**f2a[freq] - 1) * 100\n",
    "        elif formular == 'log': # Natural log\n",
    "            X.loc[:, var] = np.log(Z.loc[:, var])\n",
    "        else:\n",
    "            print('Transformation formular not found.')        \n",
    "\n",
    "    Z = Z.loc[sample_start:]\n",
    "    X = X.loc[sample_start:]\n",
    "    return X, Z\n",
    "\n",
    "def nanLE(rem1, X):\n",
    "    nanLead = rem1.cumsum() == list(range(1, rem1.shape[0] + 1))  # 위부터 연속하여 NaN인 행 식별\n",
    "    nanEnd = ((rem1.sum() - rem1.cumsum() + rem1)                 # rem1.cumsum(reverse=True)\n",
    "               == list(range(rem1.shape[0], 0, -1)))              # 아래부터 연속하여 NaN인 행 식별\n",
    "    nanLE = nanLead | nanEnd                                      # 위 또는 아래부터 연속하여 NaN인 행 식별\n",
    "    X = X.loc[~nanLE]\n",
    "    indNaN = X.isnull()\n",
    "    return X, indNaN\n",
    "\n",
    "def bdkg_index(A, A_i, b):\n",
    "    index = [(bb, ii, jj) for bb, ii, jj in A.index] + [(b, ii, jj) for ii, jj in A_i.index]\n",
    "    columns = [(bb, ii, jj) for bb, ii, jj in A.columns] + [(b, ii, jj) for ii, jj in A_i.columns]\n",
    "    A = pd.DataFrame(block_diag(A, A_i), index=index, columns=columns)\n",
    "    return A\n",
    "\n",
    "def bkdg_flat_index(A, B):\n",
    "    index = A.index.to_flat_index().tolist() + B.index.to_flat_index().tolist()\n",
    "    columns = A.columns.to_flat_index().tolist() + B.columns.to_flat_index().tolist()\n",
    "    A = pd.DataFrame(block_diag(A, B), index=index, columns=columns)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remNans_spline, filtering, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     18
    ]
   },
   "outputs": [],
   "source": [
    "def filtering(X, k):\n",
    "    Y = X.copy()\n",
    "    for var in X.columns:\n",
    "        x = X[var].copy()\n",
    "        isnanx = x.isnull()\n",
    "        t1 = isnanx[isnanx.eq(False)].index[0]\n",
    "        t2 = isnanx[isnanx.eq(False)].index[-1]\n",
    "        x[t1:t2] = x[t1:t2].interpolate('cubic')  # GDPC1 with method 2: 1.4759/1.4731, 1.4277/1.4151 (matlab/python)\n",
    "        isnanx = x.isnull()\n",
    "        x.loc[x.isnull()] = x.median(skipna=True)\n",
    "        x_ext = np.append(np.append([x.values[0]]*k, x.values), [x.values[-1]]*k)\n",
    "        x_ma = lfilter(np.ones(2*k+1)/(2*k+1), 1, x_ext)  # equivalent to filter() in MATLAB\n",
    "        x_ma = x_ma[2*k:]\n",
    "        x_repl = pd.Series(x_ma, index=x.index)\n",
    "        x[isnanx] = x_repl[isnanx]                # very similar to matlab; 1.7855/1.7851, 1.8790/1.8795 (matlab/python)\n",
    "        Y.loc[:, var] = x\n",
    "    return Y\n",
    "\n",
    "def remNaNs_spline(X, optNaN): # spline without NaNs\n",
    "    indNaN = X.isnull()\n",
    "    T, N = X.shape\n",
    "\n",
    "    if optNaN.method==1:     # replace all the missing values\n",
    "        for var in X.columns:\n",
    "            x = X[var].copy()\n",
    "            isnanx = x.isnull()\n",
    "            x.loc[isnanx] = x.median(skipna=True)\n",
    "            x_ext = np.append(np.append([x.values[0]]*optNaN.k, x.values), [x.values[-1]]*optNaN.k)\n",
    "            x_ma = lfilter(np.ones(2*optNaN.k+1)/(2*optNaN.k+1), 1, x_ext)\n",
    "            x_ma = x_ma[2*k:]\n",
    "            x_repl = pd.Series(x_ma, index=x.index)\n",
    "            x[isnanx] = x_repl[isnanx]\n",
    "            X[var] = x\n",
    "        \n",
    "    elif optNaN.method==2:   # replace missing values after removing leading and closing zeros\n",
    "        rem1 = indNaN.sum(axis=1) > .8 * N                            # 80% 이상 변수의 값이 NaN인 행 식별(NaN행)\n",
    "        X, indNaN = nanLE(rem1, X)\n",
    "        X = filtering(X, optNaN.k)\n",
    "            \n",
    "    elif optNaN.method==3: # only remove rows with leading and closing zeros\n",
    "        rem1 = indNaN.sum(axis=1) == N                                # 모든 변수의 값이 NaN인 행 식별(NaN행)\n",
    "        X, indNaN = nanLE(rem1, X)\n",
    "        \n",
    "    elif optNaN.method==4:  # remove rows with leading and closing zeros & replace missing values\n",
    "        rem1 = indNaN.sum(axis=1) == N                                # 모든 변수의 값이 NaN인 행 식별(NaN행)\n",
    "        X, indNaN = nanLE(rem1, X)\n",
    "        X = filtering(X, optNaN.k)\n",
    "        \n",
    "    elif optNaN.method==5:  # replace missing values  \n",
    "        indNaN = X.isnull()\n",
    "        X = filtering(X, optNaN.k)\n",
    "    \n",
    "    return X, indNaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman filter/smoother"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MissData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def MissData(y, C, R):\n",
    "    # Syntax:\n",
    "    # Description:\n",
    "    #   Eliminates the rows in y & matrices C, R that correspond to missing \n",
    "    #   data (NaN) in y\n",
    "    #\n",
    "    # Input:\n",
    "    #   y: Vector of observations at time t\n",
    "    #   C: Observation matrix\n",
    "    #   R: Covariance for observation matrix residuals\n",
    "    #\n",
    "    # Output:\n",
    "    #   y: Vector of observations at time t (reduced)     \n",
    "    #   C: Observation matrix (reduced)     \n",
    "    #   R: Covariance for observation matrix residuals\n",
    "    #   L: Used to restore standard dimensions(n x #) where # is the nr of \n",
    "    #      available data in y\n",
    "\n",
    "    # Returns 1 for nonmissing series\n",
    "    ix = ~np.isnan(y)\n",
    "\n",
    "    # Index for columns with nonmissing variables\n",
    "    e = np.eye(y.shape[0])\n",
    "    L = e[:, ix]\n",
    "\n",
    "    # Removes missing series\n",
    "    y = y[ix]\n",
    "\n",
    "    # Removes missing series from observation matrix\n",
    "    C = C[ix, :]\n",
    "\n",
    "    # Removes missing series from transition matrix\n",
    "    R = R[ix, ix]\n",
    "\n",
    "    return y, C, R, L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def FIS(A, Zm, ZmU, Vm, VmU, loglik, k_t):\n",
    "    # Applies fixed-interval smoother\n",
    "    #\n",
    "    #  Description:\n",
    "    #    SKF() applies a fixed-interval smoother, and is used in conjunction \n",
    "    #    with SKF(). See  page 154 of 'Forecasting, structural time series models \n",
    "    #    and the Kalman filter' for more details (Harvey, 1990).\n",
    "    #\n",
    "    #  Input parameters:\n",
    "    #    A: m-by-m transition matrix \n",
    "    #    S: structure returned by SKF() \n",
    "            #    S.Zm: m-by-nobs matrix, prior/predicted factor state vector\n",
    "            #          (S.Zm(:,t) = Z_t|t-1)\n",
    "            #    S.ZmU: m-by-(nobs+1) matrix, posterior/updated state vector\n",
    "            #           (S.Zm(t+1) = Z_t|t)\n",
    "            #    S.Vm: m-by-m-by-nobs array, prior/predicted covariance of factor\n",
    "            #          state vector (S.Vm(:,:,t) = V_t|t-1)  \n",
    "            #    S.VmU: m-by-m-by-(nobs+1) array, posterior/updated covariance of\n",
    "            #           factor state vector (S.VmU(:,:,t+1) = V_t|t)\n",
    "            #    S.loglik: scalar, value of likelihood function\n",
    "            #    S.k_t: k-by-m Kalman gain\n",
    "    #\n",
    "    #  Output parameters:\n",
    "    #    S: FIS() adds the following smoothed estimates to the S structure: \n",
    "    #    - S.ZmT: m-by-(nobs+1) matrix, smoothed states\n",
    "    #             (S.ZmT(:,t+1) = Z_t|T) \n",
    "    #    - S.VmT: m-by-m-by-(nobs+1) array, smoothed factor covariance\n",
    "    #             matrices (S.VmT(:,:,t+1) = V_t|T = Cov(Z_t|T))\n",
    "    #    - S.VmT_1: m-by-m-by-nobs array, smoothed lag 1 factor covariance\n",
    "    #               matrices (S.VmT_1(:,:,t) = Cov(Z_t Z_t-1|T))\n",
    "    #\n",
    "    #  Model:\n",
    "    #   Y_t = C_t Z_t + e_t for e_t ~ N(0, R)\n",
    "    #   Z_t = A Z_{t-1} + mu_t for mu_t ~ N(0, Q)\n",
    "\n",
    "    ## ORGANIZE INPUT ---------------------------------------------------------\n",
    "    # Initialize output matrices    \n",
    "    nobs, m = Zm.shape\n",
    "    ZmT = np.zeros((nobs+1,m))\n",
    "    VmT = np.zeros((nobs+1,m,m))\n",
    "\n",
    "    # Fill the final period of ZmT, VmT with SKF() posterior values\n",
    "    ZmT[nobs,:] = ZmU[nobs, :].squeeze()\n",
    "    VmT[nobs,:,:] = VmU[nobs,:,:].squeeze()\n",
    "\n",
    "    # Initialize VmT_1 lag 1 covariance matrix for final period\n",
    "    VmT_1 = np.zeros((nobs,m,m))\n",
    "    VmT_1[nobs-1,:,:] = (np.eye(m)-k_t).dot(A).dot(VmU[nobs-1,:,:].squeeze())\n",
    "\n",
    "    # Used for recursion process. See companion file for details\n",
    "    J_2 = VmU[nobs-1,:,:].squeeze().dot(A.T).dot(pinv(Vm[nobs-1,:,:]))\n",
    "\n",
    "    \n",
    "    ## RUN SMOOTHING ALGORITHM ----------------------------------------------\n",
    "    # Loop through time reverse-chronologically (starting at final period nobs)\n",
    "    for t in range(nobs-1, -1, -1):\n",
    "        # Store posterior and prior factor covariance values \n",
    "        VmUt = VmU[t,:,:].squeeze()\n",
    "        Vmt = Vm[t,:,:].squeeze()\n",
    "        \n",
    "        # Store previous period smoothed factor covariance and lag-1 covariance\n",
    "        VmT_t_1 = VmT[t+1,:,:].squeeze()\n",
    "        VmT_1t = VmT_1[t,:,:].squeeze()\n",
    "        \n",
    "        J_1 = J_2\n",
    "        \n",
    "        # Update smoothed factor estimate\n",
    "        ZmT[t,:] = ZmU[t,:] + J_1.dot(ZmT[t+1,:] - A.dot(ZmU[t,:]))\n",
    "        \n",
    "        # Update smoothed factor covariance matrix\n",
    "        VmT[t,:,:] = VmUt + J_1.dot(VmT_t_1 - Vmt).dot(J_1.T)\n",
    "        \n",
    "        \n",
    "        if t > 0:\n",
    "            # Update weight\n",
    "            J_2 = VmU[t-1,:,:].squeeze().dot(A.T).dot(pinv(Vm[t-1,:,:].squeeze()))\n",
    "            \n",
    "            # Update lag 1 factor covariance matrix \n",
    "            VmT_1[t-1,:,:] = VmUt.dot(J_2.T) + J_1.dot(VmT_1t - A.dot(VmUt)).dot(J_2.T)\n",
    "            \n",
    "\n",
    "    return ZmT, VmT, VmT_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def SKF(Y, A, C, Q, R, Z_0, V_0):\n",
    "    #  Description:\n",
    "    #    SKF() applies the Kalman filter\n",
    "    #\n",
    "    #  Input parameters:\n",
    "    #    Y: k-by-nobs matrix of input data\n",
    "    #    A: m-by-m transition matrix \n",
    "    #    C: k-by-m observation matrix\n",
    "    #    Q: m-by-m covariance matrix for transition equation residuals (mu_t)\n",
    "    #    R: k-by-k covariance for observation matrix residuals (e_t)\n",
    "    #    Z_0: 1-by-m vector, initial value of state\n",
    "    #    V_0: m-by-m matrix, initial value of state covariance matrix\n",
    "    #\n",
    "    #  Output parameters:\n",
    "    #    S.Zm: m-by-nobs matrix, prior/predicted factor state vector\n",
    "    #          (S.Zm(:,t) = Z_t|t-1)\n",
    "    #    S.ZmU: m-by-(nobs+1) matrix, posterior/updated state vector\n",
    "    #           (S.Zm(t+1) = Z_t|t)\n",
    "    #    S.Vm: m-by-m-by-nobs array, prior/predicted covariance of factor\n",
    "    #          state vector (S.Vm(:,:,t) = V_t|t-1)  \n",
    "    #    S.VmU: m-by-m-by-(nobs+1) array, posterior/updated covariance of\n",
    "    #           factor state vector (S.VmU(:,:,t+1) = V_t|t)\n",
    "    #    S.loglik: scalar, value of likelihood function\n",
    "    #    S.k_t: k-by-m Kalman gain\n",
    "\n",
    "    ## INITIALIZE OUTPUT VALUES ---------------------------------------------   \n",
    "    # Output structure & dimensions of state space matrix\n",
    "    k, m = C.shape   # k * m: observable variables and factors\n",
    "\n",
    "    # Outputs time for data matrix. \"number of observations\"\n",
    "    nobs  = Y.shape[1]\n",
    "\n",
    "    # Instantiate output\n",
    "    Zm     = np.ones((nobs, m)) * np.nan       # Z_t | t-1 (prior)\n",
    "    Vm     = np.ones((nobs, m, m)) * np.nan    # V_t | t-1 (prior)\n",
    "    ZmU    = np.ones((nobs+1, m)) * np.nan;    # Z_t | t (posterior/updated)\n",
    "    VmU    = np.ones((nobs+1, m, m)) * np.nan; # V_t | t (posterior/updated)\n",
    "    loglik = 0\n",
    "\n",
    "    ## SET INITIAL VALUES ----------------------------------------------------\n",
    "    Zu = Z_0.copy()  # Z_0|0 (In below loop, Zu gives Z_t | t)\n",
    "    Vu = V_0.copy()  # V_0|0 (In below loop, Vu guvse V_t | t)\n",
    "\n",
    "    # Store initial values\n",
    "    ZmU[0, :]     = Zu.copy()\n",
    "    VmU[0, :, :]  = Vu.copy()\n",
    "\n",
    "    ## KALMAN FILTER PROCEDURE ----------------------------------------------\n",
    "    for t in range(nobs):\n",
    "        \n",
    "        ### CALCULATING PRIOR DISTIBUTION----------------------------------\n",
    "        # Use transition eqn to create prior estimate for factor\n",
    "        # i.e. Z = Z_t|t-1\n",
    "        Z = A.dot(Zu)\n",
    "\n",
    "        # Prior covariance matrix of Z (i.e. V = V_t|t-1)\n",
    "        # Var(Z) = Var(A*Z+u_t) = A*Vu*A' + Q\n",
    "        V = A.dot(Vu).dot(A.T) + Q\n",
    "        V = (V+V.T)/2               # Trick to make symmetric\n",
    "\n",
    "        ### CALCULATING POSTERIOR DISTRIBUTION ----------------------------\n",
    "        # Removes missing series: These are removed from Y, C, and R\n",
    "        Y_t, C_t, R_t, L = MissData(Y[:, t], C, R)\n",
    "\n",
    "\n",
    "        # Check if y_t contains no data. If so, replace Zu and Vu with prior.\n",
    "        if Y_t.size==0:\n",
    "            Zu = Z\n",
    "            Vu = V\n",
    "        else:\n",
    "            # Steps for variance and population regression coefficients:\n",
    "            # Var(c_t*Z_t + e_t) = c_t Var(A) c_t' + Var(u) = c_t*V *c_t' + R\n",
    "            VC = V.dot(C_t.T)\n",
    "            iF = inv(C_t.dot(VC) + R_t)\n",
    "\n",
    "            # Matrix of population regression coefficients (QuantEcon eqn #4)\n",
    "            VCF = VC.dot(iF)\n",
    "\n",
    "            # Gives difference between actual and predicted observation\n",
    "            # matrix values\n",
    "            innov = Y_t - C_t.dot(Z)\n",
    "\n",
    "            # Update estimate of factor values (posterior)\n",
    "            Zu = Z  + VCF.dot(innov)\n",
    "\n",
    "            # Update covariance matrix (posterior) for time t\n",
    "            Vu = V  - VCF.dot(VC.T)\n",
    "            Vu = (Vu+Vu.T)/2 # Approximation trick to make symmetric\n",
    "\n",
    "            # Update log likelihood \n",
    "            loglik = loglik + 0.5*(log(det(iF)) - innov.T.dot(iF).dot(innov))\n",
    "\n",
    "\n",
    "        ### STORE OUTPUT----------------------------------------------------\n",
    "        # Store covariance and observation values for t-1 (priors)\n",
    "        Zm[t, :] = Z\n",
    "        Vm[t, :, :] = V\n",
    "\n",
    "        # Store covariance and state values for t (posteriors)\n",
    "        # i.e. Zu = Z_t|t   & Vu = V_t|t\n",
    "        ZmU[t+1, :] = Zu\n",
    "        VmU[t+1, :, :] = Vu\n",
    "\n",
    "\n",
    "    # Store Kalman gain k_t\n",
    "    if Y_t.size==0:\n",
    "        k_t = np.zeros((m,m))\n",
    "    else:\n",
    "        k_t = VCF.dot(C_t)\n",
    "\n",
    "    return Zm, ZmU, Vm, VmU, loglik, k_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### runKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def runKF(Y, A, C, Q, R, Z_0, V_0):\n",
    "    #  Description:\n",
    "    #    runKF() applies a Kalman filter and fixed-interval smoother. The\n",
    "    #    script uses the following model:\n",
    "    #           Y_t = C_t Z_t + e_t for e_t ~ N(0, R)\n",
    "    #           Z_t = A Z_{t-1} + mu_t for mu_t ~ N(0, Q)\n",
    "\n",
    "    #  Throughout this file:\n",
    "    #    'm' denotes the number of elements in the state vector Z_t.\n",
    "    #    'k' denotes the number of elements (observed variables) in Y_t.\n",
    "    #    'nobs' denotes the number of time periods for which data are observed.\n",
    "    #\n",
    "    #  Input parameters:\n",
    "    #    Y: k-by-nobs matrix of input data\n",
    "    #    A: m-by-m transition matrix \n",
    "    #    C: k-by-m observation matrix\n",
    "    #    Q: m-by-m covariance matrix for transition equation residuals (mu_t)\n",
    "    #    R: k-by-k covariance for observation matrix residuals (e_t)\n",
    "    #    Z_0: 1-by-m vector, initial value of state\n",
    "    #    V_0: m-by-m matrix, initial value of state covariance matrix\n",
    "    #\n",
    "    #  Output parameters:\n",
    "    #    zsmooth: k-by-(nobs+1) matrix, smoothed factor estimates\n",
    "    #             (i.e. zsmooth(:,t+1) = Z_t|T)\n",
    "    #    Vsmooth: k-by-k-by-(nobs+1) array, smoothed factor covariance matrices\n",
    "    #             (i.e. Vsmooth(:,:,t+1) = Cov(Z_t|T))\n",
    "    #    VVsmooth: k-by-k-by-nobs array, lag 1 factor covariance matrices\n",
    "    #              (i.e. Cov(Z_t,Z_t-1|T))\n",
    "    #    loglik: scalar, log-likelihood\n",
    "    #\n",
    "    #  References:\n",
    "    #  - QuantEcon's \"A First Look at the Kalman Filter\"\n",
    "    #  - Adapted from replication files for:\n",
    "    #    \"Nowcasting\", 2010, (by Marta Banbura, Domenico Giannone and Lucrezia \n",
    "    #    Reichlin), in Michael P. Clements and David F. Hendry, editors, Oxford \n",
    "    #    Handbook on Economic Forecasting.\n",
    "    #\n",
    "    # The software can be freely used in applications. \n",
    "    # Users are kindly requested to add acknowledgements to published work and \n",
    "    # to cite the above reference in any resulting publications\n",
    "    \n",
    "    states = pd.MultiIndex.from_tuples(A.index)\n",
    "    periods0 = y_est.columns\n",
    "    periods1 = pd.date_range(y_est.columns[0], y_est.columns[-1] + MonthBegin(), freq=y_est.columns.freq)\n",
    "    \n",
    "    periods0_states = pd.MultiIndex.from_tuples([(i, j, p, q) \n",
    "                                                for i in periods0 for j, p, q in states.to_flat_index()])\n",
    "    periods1_states = pd.MultiIndex.from_tuples([(i, j, p, q) \n",
    "                                                  for i in periods1 for j, p, q in states.to_flat_index()])\n",
    "    \n",
    "    Y, A, C, Q, R = Y.to_numpy(), A.to_numpy(), C.to_numpy(), Q.to_numpy(), R.to_numpy()\n",
    "    Z_0, V_0 = Z_0.to_numpy(), V_0.to_numpy()\n",
    "\n",
    "    Zm, ZmU, Vm, VmU, loglik, k_t = SKF(Y, A, C, Q, R, Z_0, V_0)   # Kalman filter\n",
    "    ZmT, VmT, VmT_1 = FIS(A, Zm, ZmU, Vm, VmU, loglik, k_t)        # Fixed interval smoother\n",
    "\n",
    "    # Organize output \n",
    "    Zsmooth = pd.DataFrame(ZmT, index=periods1, columns=states)\n",
    "    \n",
    "    VmT = VmT.reshape(VmT.shape[0]*VmT.shape[1], VmT.shape[2])\n",
    "    VmT_1 = VmT_1.reshape(VmT_1.shape[0]*VmT_1.shape[1], VmT_1.shape[2])\n",
    "    \n",
    "    Vsmooth = pd.DataFrame(VmT, index=periods1_states, columns=states)\n",
    "    VVsmooth = pd.DataFrame(VmT_1, index=periods0_states, columns=states)\n",
    "\n",
    "    return Zsmooth, Vsmooth, VVsmooth, loglik, periods0, periods1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMstep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### em_converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def em_converged(loglik, previous_loglik, threshold=1e-4, check_decreased=1):\n",
    "    #  checks whether EM algorithm has converged\n",
    "    #\n",
    "    #  Syntax:\n",
    "    #    [converged, decrease] = em_converged(loglik, previous_loglik, threshold, check_increased)\n",
    "    #\n",
    "    #  Description:\n",
    "    #    em_converged() checks whether EM has converged. Convergence occurs if\n",
    "    #    the slope of the log-likelihood function falls below 'threshold'(i.e.\n",
    "    #    f(t) - f(t-1)| / avg < threshold) where avg = (|f(t)| + |f(t-1)|)/2\n",
    "    #    and f(t) is log lik at iteration t. 'threshold' defaults to 1e-4.\n",
    "    #\n",
    "    #    This stopping criterion is from Numerical Recipes in C (pg. 423).\n",
    "    #    With MAP estimation (using priors), the likelihood can decrease\n",
    "    #    even if the mode of the posterior increases.\n",
    "    #\n",
    "    #  Input arguments:\n",
    "    #    loglik: Log-likelihood from current EM iteration\n",
    "    #    previous_loglik: Log-likelihood from previous EM iteration\n",
    "    #    threshold: Convergence threshhold. The default is 1e-4.\n",
    "    #    check_decreased: Returns text output if log-likelihood decreases.\n",
    "    #\n",
    "    #  Output:\n",
    "    #    converged (numeric): Returns 1 if convergence criteria satisfied, and 0 otherwise.\n",
    "    #    decrease (numeric): Returns 1 if loglikelihood decreased.\n",
    "\n",
    "    ## Instantiate variables\n",
    "    # Threshhold arguments: Checks default behavior\n",
    "    # if nargin < 3, threshold = 1e-4; end\n",
    "    # if nargin < 4, check_decreased = 1; end\n",
    "\n",
    "    # Initialize output\n",
    "    converged = 0;\n",
    "    decrease = 0;\n",
    "\n",
    "    ## Check if log-likelihood decreases (optional)\n",
    "    if check_decreased:\n",
    "        if loglik - previous_loglik < -1e-3: # allow for a little imprecision\n",
    "            print('loglik decreased from {,.4f} to {,.4f}'.format(previous_loglik, loglik))\n",
    "            decrease = 1\n",
    "\n",
    "    ## Check convergence criteria\n",
    "    delta_loglik = abs(loglik - previous_loglik)               # Difference in loglik\n",
    "    avg_loglik = (abs(loglik) + abs(previous_loglik) + np.spacing(1))/2\n",
    "\n",
    "    if (delta_loglik / avg_loglik) < threshold:\n",
    "        converged = 1                                          # Check convergence\n",
    "\n",
    "    return converged, decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `Spec`, `Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs.\n",
    "vintage = '2016-06-29'; # vintage dataset to use for estimation\n",
    "country = 'US';         # United States macroeconomic data\n",
    "sample_start  = '2000-01-01'; # estimation sample\n",
    "\n",
    "Spec = load_spec('Spec_US_example.xls');\n",
    "# Parse `Spec`\n",
    "# SeriesID = Spec.SeriesID; SeriesName = Spec.SeriesName; Units = Spec.Units; UnitsTransformed = Spec.UnitsTransformed;\n",
    "\n",
    "datafile = path.join('data', country, vintage + '.xls')\n",
    "X, Z = load_data(datafile, Spec, sample_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "# X.INDPRO.plot(ax=axs[0])\n",
    "# Z.INDPRO.plot(ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T, N = X.shape;\n",
    "# nQ = sum(Spec.Spec.Frequency.eq('q'));   # Number of quarterly series\n",
    "# nM = N - nQ                              # number of monthly series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = Spec.Blocks;                    # Block loading structure\n",
    "spec = Spec.Spec;                        # Block loading structure\n",
    "p = 1;                                   # Number of lags in autoregressive of factor\n",
    "r = pd.Series(np.ones(blocks.shape[1], dtype=int), \n",
    "              index=blocks.columns)  # Number of common factors for each block\n",
    "# i_idio = np.array([True] * nM + [False] * nQ);\n",
    "\n",
    "# R*Lambda = q; Contraints on the loadings of the quartrly variables\n",
    "Rcon = np.array([[2, -1,  0,  0,  0],\n",
    "                 [3,  0, -1,  0,  0],\n",
    "                 [2,  0,  0, -1,  0],\n",
    "                 [1,  0,  0,  0, -1]])\n",
    "q = np.zeros(4);\n",
    "\n",
    "## DATA Normalization and InitCond\n",
    "Mx = X.mean(skipna=True)\n",
    "Wx = X.std(skipna=True)\n",
    "xNaN = (X - Mx)/Wx        # Standardize series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InitCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "optNaN = pd.Series({'method':2, 'k':3})\n",
    "# method=2 : Remove leading and closing zeros\n",
    "# k=3      : Setting for filter(): See remNaN_spline\n",
    "\n",
    "A, C, Q, R, Z_0, V_0 = InitCond(xNaN, r, p, spec, blocks, optNaN, Rcon, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM LOOP\n",
    "\n",
    "$y_t = CZ_t + e \\newline\n",
    "Z_t = AZ_{t-1} + v, \\newline\n",
    "\\text{where} y: N \\times T, Z: pr \\times T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1e-5;  # EM loop threshold (default value)\n",
    "max_iter = 5000;   # EM loop maximum number of iterations\n",
    "\n",
    "# Initialize EM loop values\n",
    "previous_loglik = -np.inf\n",
    "num_iter = 0\n",
    "LL = -np.inf\n",
    "converged = 0\n",
    "\n",
    "# y for the estimation is WITH missing data\n",
    "y = xNaN.T\n",
    "\n",
    "# Remove the leading and ending nans\n",
    "optNaN.method = 3\n",
    "y_est = remNaNs_spline(xNaN, optNaN)[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_est.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def EMstep(y, A, C, Q, R, Z_0, V_0, r, p, Rcon, q, blocks, spec):\n",
    "#  Applies EM algorithm for parameter reestimation\n",
    "#\n",
    "#  Syntax:\n",
    "#    [C_new, R_new, A_new, Q_new, Z_0, V_0, loglik]\n",
    "#    = EMstep(y, A, C, Q, R, Z_0, V_0, r, p, Rcon, q, nQ, i_idio, blocks, spec)\n",
    "#\n",
    "#  Description:\n",
    "#    EMstep reestimates parameters based on the Estimation Maximization (EM)\n",
    "#    algorithm. This is a two-step procedure:\n",
    "#    (1) E-step: the expectation of the log-likelihood is calculated using\n",
    "#        previous parameter estimates.\n",
    "#    (2) M-step: Parameters are re-estimated through the maximisation of\n",
    "#        the log-likelihood (maximize result from (1)).\n",
    "#\n",
    "#    See \"Maximum likelihood estimation of factor models on data sets with\n",
    "#    arbitrary pattern of missing data\" for details about parameter\n",
    "#    derivation (Banbura & Modugno, 2010). This procedure is in much the\n",
    "#    same spirit.\n",
    "#\n",
    "#  Input:\n",
    "#    y:      Series data\n",
    "#    A:      Transition matrix\n",
    "#    C:      Observation matrix\n",
    "#    Q:      Covariance for transition equation residuals\n",
    "#    R:      Covariance for observation matrix residuals\n",
    "#    Z_0:    Initial values of factors\n",
    "#    V_0:    Initial value of factor covariance matrix\n",
    "#    r:      Number of common factors for each block (e.g. vector [1 1 1 1])\n",
    "#    p:      Number of lags in transition equation\n",
    "#    Rcon:  Estimation structure for quarterly variables (i.e. \"tent\")\n",
    "#    q:      Constraints on loadings\n",
    "#    nQ:     Number of quarterly series\n",
    "#    i_idio: Indices for monthly variables\n",
    "#    blocks: Block structure for each series (i.e. for a series, the structure\n",
    "#            [1 0 0 1] indicates loadings on the first and fourth factors)\n",
    "#\n",
    "#  Output:\n",
    "#    C_new: Updated observation matrix\n",
    "#    R_new: Updated covariance matrix for residuals of observation matrix\n",
    "#    A_new: Updated transition matrix\n",
    "#    Q_new: Updated covariance matrix for residuals for transition matrix\n",
    "#    Z_0:   Initial value of state\n",
    "#    V_0:   Initial value of covariance matrix\n",
    "#    loglik: Log likelihood\n",
    "#\n",
    "# References:\n",
    "#   \"Maximum likelihood estimation of factor models on data sets with\n",
    "#   arbitrary pattern of missing data\" by Banbura & Modugno (2010).\n",
    "#   Abbreviated as BM2010\n",
    "\n",
    "\n",
    "## Initialize preliminary values\n",
    "# Store series/model values\n",
    "Qv = spec.loc[spec.Frequency.eq('q')].index.tolist()\n",
    "Mv = spec.loc[spec.Frequency.eq('m')].index.tolist()\n",
    "\n",
    "n, T = y.shape\n",
    "nQ = len(Qv)\n",
    "nM = n - nQ                  # Number of monthly series\n",
    "pC = Rcon.shape[1]\n",
    "ppC = max(p,pC)\n",
    "num_blocks = blocks.shape[1] # Number of blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ESTIMATION STEP: Compute the (expected) sufficient statistics for a single\n",
    "# Kalman filter sequence\n",
    "\n",
    "# Running the Kalman filter and smoother with current parameters\n",
    "# Note that log-liklihood is NOT re-estimated after the runKF step: This\n",
    "# effectively gives the previous iteration's log-likelihood\n",
    "# For more information on output, see runKF\n",
    "Zsmooth, Vsmooth, VVsmooth, loglik, p0, p1 = runKF(y, A, C, Q, R, Z_0, V_0)   # df으로 return할 경우 시간이 오래 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAXIMIZATION STEP (TRANSITION EQUATION)\n",
    "# See (Banbura & Modugno, 2010) for details.\n",
    "\n",
    "# Initialize output\n",
    "A_new = A.copy()\n",
    "Q_new = Q.copy()\n",
    "V_0_new = V_0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### 2A. UPDATE FACTOR PARAMETERS INDIVIDUALLY ----------------------------\n",
    "for b in blocks.columns:   # Loop for each block: factors are uncorrelated\n",
    "    \n",
    "    # ESTIMATE FACTOR PORTION OF Q, A\n",
    "    # Note: EZZ, EZZ_BB, EZZ_FB are parts of equations 6 and 8 in BM 2010\n",
    "\n",
    "    # E[f_t*f_t' | Omega_T]\n",
    "    EZZ = (Zsmooth.T.loc[b, p1[1:]].dot(Zsmooth.T.loc[b, p1[1:]].T) \n",
    "           + Vsmooth.loc[idx[p1[1:], b], b].groupby(level=[1, 2, 3], axis=0).sum().loc[b])\n",
    "    \n",
    "    # E[f_{t-1}*f_{t-1}' | Omega_T]\n",
    "    EZZ_BB = (Zsmooth.T.loc[b, p1[:-1]].dot(Zsmooth.T.loc[b, p1[:-1]].T)\n",
    "              + Vsmooth.loc[idx[p1[:-1], b], b].groupby(level=[1, 2, 3], axis=0).sum().loc[b])\n",
    "\n",
    "    # E[f_t*f_{t-1}' | Omega_T]\n",
    "    EZZ_FB = (Zsmooth.T.loc[b, p1[1:]].dot(Zsmooth.shift().loc[p1[1:], b])\n",
    "              + VVsmooth.loc[idx[:, b], b].groupby(level=[1, 2, 3], axis=0).sum().loc[b])\n",
    "    \n",
    "    # Select transition matrix/covariance matrix for block i\n",
    "    A_i = A.loc[b, b]\n",
    "    Q_i = Q.loc[b, b]\n",
    "    \n",
    "    # Equation 6: Estimate VAR(p) for factor\n",
    "    A_i.loc[0, :p-1] = EZZ_FB.loc[0, :p-1].dot(inv(EZZ_BB.loc[idx[:p-1], idx[:p-1]])).values\n",
    "\n",
    "    # Equation 8: Covariance matrix of residuals of VAR\n",
    "    Q_i.loc[0, 0] = (EZZ.loc[0, 0] - A_i.loc[0, idx[:p-1]].dot(EZZ_FB.loc[0, idx[:p-1]].T)).values / T\n",
    "\n",
    "    # Place updated results in output matrix\n",
    "    A_new.loc[idx[b, :, :], idx[b, :, :]] = A_i.values\n",
    "    Q_new.loc[idx[b, :, :], idx[b, :, :]] = Q_i.values\n",
    "    V_0_new.loc[idx[b, :, :], idx[b, :, :]] = Vsmooth.loc[idx[p1[0], b], b].values\n",
    "\n",
    "### 2B. UPDATING PARAMETERS FOR IDIOSYNCRATIC COMPONENT ------------------\n",
    "\n",
    "# Below 3 estimate the idiosyncratic component (for eqns 6, 8 BM 2010)\n",
    "\n",
    "# E[f_t*f_t' | \\Omega_T]\n",
    "EZZ = (diag(diag(Zsmooth.T.loc[spec.index, p1[1:]].dot(Zsmooth.T.loc[spec.index, p1[1:]].T))) + \n",
    "       Vsmooth.loc[idx[p1[1:], spec.index], spec.index].groupby(level=[1,2,3],axis=0, sort=False).sum())\n",
    "\n",
    "# E[f_{t-1}*f_{t-1}' | \\Omega_T]\n",
    "EZZ_BB = (diag(diag(Zsmooth.shift(1).T.loc[spec.index, p1[1:]].dot(Zsmooth.shift(1).T.loc[spec.index, p1[1:]].T))) + \n",
    "          Vsmooth.loc[idx[p1[:-1], spec.index], spec.index].groupby(level=[1,2,3],axis=0, sort=False).sum())\n",
    "\n",
    "# E[f_t*f_{t-1}' | \\Omega_T]\n",
    "EZZ_FB = (diag(diag(Zsmooth.T.loc[spec.index, p1[1:]].dot(Zsmooth.shift(1).T.loc[spec.index, p1[1:]].T))) + \n",
    "          VVsmooth.loc[idx[:, spec.index], spec.index].groupby(level=[1,2,3],axis=0, sort=False).sum())\n",
    "\n",
    "A_i = EZZ_FB.dot(diag(1 / diag(EZZ_BB))) # Equation 6\n",
    "A_i.columns = A_i.index\n",
    "\n",
    "Q_i = (EZZ - A_i.values.dot(EZZ_FB.T)) / T # Equation 8\n",
    "\n",
    "# Place updated results in output matrix\n",
    "A_new.loc[idx[Mv, :, :], idx[Mv, :, :]] = A_i.loc[Mv, Mv].values\n",
    "Q_new.loc[idx[Mv, :, :], idx[Mv, :, :]] = Q_i.loc[Mv, Mv].values\n",
    "V_0_new.loc[idx[Mv, :, :], idx[Mv, :, :]] = diag(diag(Vsmooth.loc[idx[p1[0], Mv], Mv]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Global'] SeriesID\n",
      "CPIAUCSL    197\n",
      "CPILFESL    197\n",
      "IQ          197\n",
      "IR          197\n",
      "PCEPI       197\n",
      "PCEPILFE    197\n",
      "dtype: int64\n",
      "['Global', 'Soft'] SeriesID\n",
      "GACDFSA066MSFRBPHI    198\n",
      "GACDISA066MSFRBNY     180\n",
      "dtype: int64\n",
      "['Global', 'Real'] SeriesID\n",
      "BOPTEXP    196\n",
      "BOPTIMP    196\n",
      "BUSINV     196\n",
      "DGORDER    197\n",
      "DSPIC96    197\n",
      "HOUST      197\n",
      "INDPRO     197\n",
      "PCEC96     197\n",
      "PERMIT     197\n",
      "RSAFS      197\n",
      "TCU        197\n",
      "TTLCONS    196\n",
      "dtype: int64\n",
      "['Global', 'Labor'] SeriesID\n",
      "JTSJOL    184\n",
      "PAYEMS    197\n",
      "UNRATE    197\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## 3 MAXIMIZATION STEP (observation equation)\n",
    "\n",
    "### INITIALIZATION AND SETUP ----------------------------------------------\n",
    "Z_0 = Zsmooth.loc[p1[0]] # zeros(size(Zsmooth,1),1); #\n",
    "\n",
    "# Set missing data series values to 0\n",
    "nanY = y.isnull()\n",
    "y[nanY] = 0\n",
    "\n",
    "# LOADINGS\n",
    "C_new = C.copy()\n",
    "\n",
    "R_con = np.empty((0, 0), int)\n",
    "q_con = np.empty((0, 1), int)\n",
    "\n",
    "for i, r_i in enumerate(r):\n",
    "    R_con = block_diag(R_con, kron(Rcon, eye(r_i)))\n",
    "    q_con = np.append(q_con, np.zeros((r_i*Rcon.shape[0], 1)), axis=0)\n",
    "\n",
    "blocks_sum = blocks.copy()\n",
    "blocks_sum['bc'] = blocks.dot([1, 2, 3, 4])\n",
    "blocks_sum = blocks_sum.set_index('bc', append=True).reorder_levels([1, 0],axis=0).sort_index(axis=0)\n",
    "\n",
    "for i, row in blocks_sum.drop_duplicates().eq(1).iloc[:4].iterrows():\n",
    "    bs = blocks_sum.drop_duplicates().columns[row].tolist()\n",
    "    rs = sum(r[bs])\n",
    "    idx_iM = [v for v in blocks_sum.loc[i[0]].index.tolist() if v in Mv]\n",
    "    n_i = len(idx_iM)  \n",
    "\n",
    "    # Initialize sums in equation 13 of BGR 2010\n",
    "    denom = np.zeros((n_i*rs,n_i*rs))\n",
    "    nom = np.zeros((n_i,rs))\n",
    "\n",
    "    AA = (Zsmooth.T.loc[idx[bs, 0, :], p1[1:]].dot(Zsmooth.T.loc[idx[bs, 0, :], p1[1:]].T) \n",
    "          + Vsmooth.loc[idx[p1[1:], bs, 0, :], idx[bs, 0, :]].groupby(level=[1,2,3],axis=0).sum())\n",
    "    \n",
    "    print(bs, (~nanY.loc[idx_iM, :]).sum(axis=1))\n",
    "    ### UPDATE MONTHLY VARIABLES: Loop through each period ----------------\n",
    "    for i, t in enumerate(p0):\n",
    "        Wt = diag(~nanY.loc[idx_iM, t]);  # Gives selection matrix (1 for nonmissing values)\n",
    "\n",
    "#         # E[f_t*t_t' | Omega_T]\n",
    "#         denom = (denom + kron(Zsmooth.T.loc[idx[bs, 0], [p1[i+1]]].dot(Zsmooth.T.loc[idx[bs, 0], [p1[i+1]]].T) \n",
    "#                               + Vsmooth.loc[idx[p1[i+1], bs, 0], idx[bs, 0]].loc[p1[i+1]], Wt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 36)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kron(np.ones((n_i*rs,n_i*rs)), Wt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "        denom = (denom + kron(Zsmooth.T.loc[idx[bs, 0, :], p1[i+1]].dot(Zsmooth.T.loc[idx[bs, 0, :], p1[i+1]].T) \n",
    "                              + Vsmooth.loc[idx[p1[i+1], bs, 0, :], idx[bs, 0, :]], Wt))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocks\n",
    "bl = unique(blocks,'rows');  # Gives unique loadings\n",
    "n_bl = size(bl,1);           # Number of unique loadings\n",
    "\n",
    "# Initialize indices: These later help with subsetting\n",
    "bl_idxM = [];  # Indicator for monthly factor loadings\n",
    "bl_idxQ = [];  # Indicator for quarterly factor loadings\n",
    "R_con = [];    # Block diagonal matrix giving monthly-quarterly aggreg scheme\n",
    "q_con = [];\n",
    "\n",
    "# Loop through each block\n",
    "for i = 1:num_blocks\n",
    "    bl_idxQ = [bl_idxQ repmat(bl(:,i),1,r(i)*ppC)];\n",
    "    bl_idxM = [bl_idxM repmat(bl(:,i),1,r(i)) zeros(n_bl,r(i)*(ppC-1))];\n",
    "    R_con = blkdiag(R_con, kron(Rcon,eye(r(i))));\n",
    "    q_con = [q_con;zeros(r(i)*size(Rcon,1),1)];\n",
    "end\n",
    "\n",
    "# Indicator for monthly/quarterly blocks in observation matrix\n",
    "bl_idxM = logical(bl_idxM);\n",
    "bl_idxQ = logical(bl_idxQ);\n",
    "\n",
    "i_idio_M = i_idio(1:nM);            # Gives 1 for monthly series           [1 1 ... 1] = [1]*23\n",
    "n_idio_M = length(find(i_idio_M));  # Number of monthly series             23\n",
    "c_i_idio = cumsum(i_idio);          # Cumulative number of monthly series  [1 2 ... 23 23 23]\n",
    "\n",
    "for i = 1:n_bl  # Loop through unique loadings (e.g. [1 0 0 0], [1 1 0 0])\n",
    "\n",
    "    bl_i = bl(i,:);\n",
    "    rs = sum(r(logical(bl_i)));                    # Total num of blocks loaded -> num of factors in loaded blocks\n",
    "    idx_i = find(ismember(blocks, bl_i, 'rows'));  # Indices for bl_i\n",
    "    idx_iM = idx_i(idx_i<nM+1);                    # Only monthly\n",
    "    n_i = length(idx_iM);                          # Number of monthly series\n",
    "\n",
    "    # Initialize sums in equation 13 of BGR 2010\n",
    "    denom = zeros(n_i*rs,n_i*rs);\n",
    "    nom = zeros(n_i,rs);\n",
    "\n",
    "    # Stores monthly indicies. These are done for input robustness\n",
    "    i_idio_i = i_idio_M(idx_iM);\n",
    "    i_idio_ii = c_i_idio(idx_iM);\n",
    "    i_idio_ii = i_idio_ii(i_idio_i);\n",
    "\n",
    "    ### UPDATE MONTHLY VARIABLES: Loop through each period ----------------\n",
    "    for t = 1:T\n",
    "        Wt = diag(~nanY(idx_iM, t));  # Gives selection matrix (1 for nonmissing values)\n",
    "\n",
    "        denom = denom +...  # E[f_t*t_t' | Omega_T]\n",
    "                kron(Zsmooth(bl_idxM(i, :), t+1) * Zsmooth(bl_idxM(i, :), t+1)' + ...\n",
    "                Vsmooth(bl_idxM(i, :), bl_idxM(i, :), t+1), Wt);\n",
    "\n",
    "        nom = nom + ...  E[y_t*f_t' | \\Omega_T]\n",
    "              y(idx_iM, t) * Zsmooth(bl_idxM(i, :), t+1)' - ...\n",
    "              Wt(:, i_idio_i) * (Zsmooth(rp1 + i_idio_ii, t+1) * ...\n",
    "              Zsmooth(bl_idxM(i, :), t+1)' + ...\n",
    "              Vsmooth(rp1 + i_idio_ii, bl_idxM(i, :), t+1));\n",
    "    end\n",
    "\n",
    "    vec_C = inv(denom)*nom(:);  # Eqn 13 BGR 2010\n",
    "\n",
    "    # Place updated monthly results in output matrix\n",
    "    C_new(idx_iM,bl_idxM(i,:)) = reshape(vec_C, n_i, rs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ### UPDATE QUARTERLY VARIABLES -----------------------------------------\n",
    "\n",
    "   idx_iQ = idx_i(idx_i > nM);  # Index for quarterly series\n",
    "   rps = rs * ppC;\n",
    "\n",
    "   # Monthly-quarterly aggregation scheme\n",
    "   R_con_i = R_con(:,bl_idxQ(i,:));\n",
    "   q_con_i = q_con;\n",
    "\n",
    "   no_c = ~(any(R_con_i,2));\n",
    "   R_con_i(no_c,:) = [];\n",
    "   q_con_i(no_c,:) = [];\n",
    "\n",
    "   # Loop through quarterly series in loading. This parallels monthly code\n",
    "   for j = idx_iQ'\n",
    "       # Initialization\n",
    "       denom = zeros(rps,rps);\n",
    "       nom = zeros(1,rps);\n",
    "\n",
    "       idx_jQ = j-nM;  # Ordinal position of quarterly variable\n",
    "       # Loc of factor structure corresponding to quarterly var residuals\n",
    "       i_idio_jQ = (rp1 + n_idio_M + 5*(idx_jQ-1)+1:rp1+ n_idio_M + 5*idx_jQ);\n",
    "\n",
    "       # Place quarterly values in output matrix\n",
    "       V_0_new(i_idio_jQ, i_idio_jQ) = Vsmooth(i_idio_jQ, i_idio_jQ,1);\n",
    "       A_new(i_idio_jQ(1), i_idio_jQ(1)) = A_i(i_idio_jQ(1)-rp1, i_idio_jQ(1)-rp1);\n",
    "       Q_new(i_idio_jQ(1), i_idio_jQ(1)) = Q_i(i_idio_jQ(1)-rp1, i_idio_jQ(1)-rp1);\n",
    "\n",
    "       for t=1:T\n",
    "           Wt = diag(~nanY(j,t));  # Selection matrix for quarterly values\n",
    "\n",
    "           # Intermediate steps in BGR equation 13\n",
    "           denom = denom + ...\n",
    "                   kron(Zsmooth(bl_idxQ(i,:), t+1) * Zsmooth(bl_idxQ(i,:), t+1)'...\n",
    "                 + Vsmooth(bl_idxQ(i,:), bl_idxQ(i,:), t+1), Wt);\n",
    "           nom = nom + y(j, t)*Zsmooth(bl_idxQ(i,:), t+1)';\n",
    "           nom = nom -...\n",
    "                Wt * ([1 2 3 2 1] * Zsmooth(i_idio_jQ,t+1) * ...\n",
    "                Zsmooth(bl_idxQ(i,:),t+1)'+...\n",
    "                [1 2 3 2 1]*Vsmooth(i_idio_jQ,bl_idxQ(i,:),t+1));\n",
    "       end\n",
    "\n",
    "        C_i = inv(denom) * nom';\n",
    "        C_i_constr = C_i - ...  # BGR equation 13\n",
    "                     inv(denom) * R_con_i'*inv(R_con_i*inv(denom)*R_con_i') * (R_con_i*C_i-q_con_i);\n",
    "\n",
    "        # Place updated values in output structure\n",
    "        C_new(j,bl_idxQ(i,:)) = C_i_constr;\n",
    "   end\n",
    "end\n",
    "\n",
    "### 3B. UPDATE COVARIANCE OF RESIDUALS FOR OBSERVATION EQUATION -----------\n",
    "# Initialize covariance of residuals of observation equation\n",
    "R_new = zeros(n,n);\n",
    "for t=1:T\n",
    "    Wt = diag(~nanY(:,t));  # Selection matrix\n",
    "    R_new = R_new + (y(:,t) - ...  # BGR equation 15\n",
    "            Wt * C_new * Zsmooth(:, t+1)) * (y(:,t) - Wt*C_new*Zsmooth(:,t+1))'...\n",
    "           + Wt*C_new*Vsmooth(:,:,t+1)*C_new'*Wt + (eye(n)-Wt)*R*(eye(n)-Wt);\n",
    "end\n",
    "\n",
    "\n",
    "R_new = R_new/T;\n",
    "RR = diag(R_new); #RR(RR<1e-2) = 1e-2;\n",
    "RR(i_idio_M) = 1e-04;  # Ensure non-zero measurement error. See Doz, Giannone, Reichlin (2012) for reference.\n",
    "RR(nM+1:end) = 1e-04;\n",
    "R_new = diag(RR);\n",
    "\n",
    "return C_new, R_new, A_new, Q_new, Z_0, V_0, loglik"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
